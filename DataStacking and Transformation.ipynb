{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d10171bc-1085-4fa0-a37d-42df189a30c6",
   "metadata": {},
   "source": [
    "Data Stacking and Transformation (Concatenating Server Logs)\n",
    "Simulate collecting partial server log statistics (different times, same metrics) from two separate servers and stack them together to analyze the global distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca2b754b-8ec1-4c6b-a82f-9aba667d3743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Data Concatenation (Stacking Observations) ---\n",
      "\n",
      "Global Stacked Logs (Servers A & B):\n",
      "   Server_ID           Timestamp  CPU_Usage  Memory_Load\n",
      "0    A_East 1900-01-01 09:00:00         65           40\n",
      "1    A_East 1900-01-01 09:15:00         70           42\n",
      "2    A_East 1900-01-01 09:30:00         72           45\n",
      "3    A_East 1900-01-01 09:45:00         68           41\n",
      "4    B_West 1900-01-01 16:00:00         85           60\n",
      "5    B_West 1900-01-01 16:15:00         90           65\n",
      "6    B_West 1900-01-01 16:30:00         88           62\n",
      "7    B_West 1900-01-01 16:45:00         92           68\n",
      "\n",
      "--- 2. Transformed (Long) Format for Analysis ---\n",
      "  Server_ID           Timestamp     Metric  Value\n",
      "0    A_East 1900-01-01 09:00:00  CPU_Usage     65\n",
      "1    A_East 1900-01-01 09:15:00  CPU_Usage     70\n",
      "2    A_East 1900-01-01 09:30:00  CPU_Usage     72\n",
      "3    A_East 1900-01-01 09:45:00  CPU_Usage     68\n",
      "4    B_West 1900-01-01 16:00:00  CPU_Usage     85\n",
      "\n",
      "--- 3. Aggregated Analysis ---\n",
      "Average Load Across All Servers:\n",
      " Metric\n",
      "CPU_Usage      78.750\n",
      "Memory_Load    52.875\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "--- 4. Concatenated Attributes (Axis=1, Inner Join) ---\n",
      "Server A Performance combined with Server C Latency:\n",
      "                      CPU_Usage  Memory_Load Server_ID  Network_Latency_ms\n",
      "Timestamp                                                                \n",
      "1900-01-01 09:00:00         65           40   C_South                  12\n",
      "1900-01-01 09:15:00         70           42   C_South                  15\n",
      "1900-01-01 09:30:00         72           45   C_South                  10\n",
      "1900-01-01 09:45:00         68           41   C_South                  18\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "def create_mock_server_logs():\n",
    "    \"\"\"Creates mock log data from two different server regions (different time periods).\"\"\"\n",
    "    \n",
    "    # DF 1: Server A (Early Shift Data)\n",
    "    df_server_a = pd.DataFrame({\n",
    "        'Server_ID': 'A_East',\n",
    "        # FIX: Specify format='%H:%M' to tell pandas exactly how to parse the time string.\n",
    "        'Timestamp': pd.to_datetime(['09:00', '09:15', '09:30', '09:45'], format='%H:%M'),\n",
    "        'CPU_Usage': [65, 70, 72, 68],\n",
    "        'Memory_Load': [40, 42, 45, 41]\n",
    "    })\n",
    "    \n",
    "    # DF 2: Server B (Late Shift Data - Same Columns)\n",
    "    df_server_b = pd.DataFrame({\n",
    "        'Server_ID': 'B_West',\n",
    "        # FIX: Specify format='%H:%M'\n",
    "        'Timestamp': pd.to_datetime(['16:00', '16:15', '16:30', '16:45'], format='%H:%M'),\n",
    "        'CPU_Usage': [85, 90, 88, 92],\n",
    "        'Memory_Load': [60, 65, 62, 68]\n",
    "    })\n",
    "    \n",
    "    # DF 3: Server C (Different Metrics - For Axis=1 Concatenation Example)\n",
    "    df_server_c = pd.DataFrame({\n",
    "        'Server_ID': 'C_South',\n",
    "        # FIX: Specify format='%H:%M'\n",
    "        'Timestamp': pd.to_datetime(['09:00', '09:15', '09:30', '09:45'], format='%H:%M'),\n",
    "        'Network_Latency_ms': [12, 15, 10, 18],\n",
    "    })\n",
    "    \n",
    "    return df_server_a, df_server_b, df_server_c\n",
    "\n",
    "\n",
    "def stack_and_pivot_server_data():\n",
    "    df_a, df_b, df_c = create_mock_server_logs()\n",
    "    \n",
    "    print(\"--- 1. Data Concatenation (Stacking Observations) ---\")\n",
    "    \n",
    "    # --- Integration Step (Concatenate Axis=0: Stacking Rows) ---\n",
    "    # This combines observations from A and B into one large time-series pool.\n",
    "    # This increases the volume of observations, as described in the lecture (axis=0).\n",
    "    global_logs_stacked = pd.concat([df_a, df_b], axis=0, ignore_index=True)\n",
    "    \n",
    "    print(\"\\nGlobal Stacked Logs (Servers A & B):\\n\", global_logs_stacked)\n",
    "    \n",
    "    # --- Transformation Step (Melt/Unpivot) ---\n",
    "    # Convert the wide format (CPU_Usage, Memory_Load) into a long format \n",
    "    # (Metric Name, Metric Value) for easier visualization/analysis.\n",
    "    logs_long_format = global_logs_stacked.melt(\n",
    "        id_vars=['Server_ID', 'Timestamp'], \n",
    "        value_vars=['CPU_Usage', 'Memory_Load'], \n",
    "        var_name='Metric', \n",
    "        value_name='Value'\n",
    "    )\n",
    "    \n",
    "    print(\"\\n--- 2. Transformed (Long) Format for Analysis ---\")\n",
    "    print(logs_long_format.head(5))\n",
    "    \n",
    "    # --- Analysis Step (Grouping and Aggregation) ---\n",
    "    # Find the average load across all servers for each metric.\n",
    "    avg_load_by_metric = logs_long_format.groupby('Metric')['Value'].mean()\n",
    "    \n",
    "    print(\"\\n--- 3. Aggregated Analysis ---\")\n",
    "    print(\"Average Load Across All Servers:\\n\", avg_load_by_metric)\n",
    "    \n",
    "    # --- Example of Axis=1 Concatenation (Combining Attributes) ---\n",
    "    # Simulate combining Server A's performance metrics with Server C's network metrics \n",
    "    # based on their shared Timestamp/index (axis=1).\n",
    "    df_c.set_index('Timestamp', inplace=True)\n",
    "    df_a_subset = df_a[['Timestamp', 'CPU_Usage', 'Memory_Load']].set_index('Timestamp')\n",
    "    \n",
    "    combined_attributes = pd.concat([df_a_subset, df_c], axis=1, join='inner')\n",
    "    print(\"\\n--- 4. Concatenated Attributes (Axis=1, Inner Join) ---\")\n",
    "    print(\"Server A Performance combined with Server C Latency:\\n\", combined_attributes)\n",
    "\n",
    "\n",
    "stack_and_pivot_server_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be436b8-b0ca-4d96-96a7-9ca5150d2321",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
